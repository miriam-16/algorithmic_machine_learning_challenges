{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:35:33.979508Z",
     "iopub.status.busy": "2025-05-06T14:35:33.979102Z",
     "iopub.status.idle": "2025-05-06T14:35:33.990040Z",
     "shell.execute_reply": "2025-05-06T14:35:33.988923Z",
     "shell.execute_reply.started": "2025-05-06T14:35:33.979481Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageDraw\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn as nn\n",
    "from torchvision import utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:35:33.994438Z",
     "iopub.status.busy": "2025-05-06T14:35:33.994053Z",
     "iopub.status.idle": "2025-05-06T14:35:34.045925Z",
     "shell.execute_reply": "2025-05-06T14:35:34.044975Z",
     "shell.execute_reply.started": "2025-05-06T14:35:33.994411Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id  has_cactus\n",
      "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
      "1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
      "2  000d1e9a533f62e55c289303b072733d.jpg           1\n",
      "3  0011485b40695e9138e92d0b3fb55128.jpg           1\n",
      "4  0014d7a11e90b62848904c1418fc8cf2.jpg           1\n"
     ]
    }
   ],
   "source": [
    "path = \"/kaggle/input/aml-challenge1\"\n",
    "import pandas as pd\n",
    "\n",
    "labels_df = pd.read_csv(path+'/train.csv')  # Adjust filename\n",
    "print(labels_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:35:34.048248Z",
     "iopub.status.busy": "2025-05-06T14:35:34.047869Z",
     "iopub.status.idle": "2025-05-06T14:35:34.063187Z",
     "shell.execute_reply": "2025-05-06T14:35:34.062243Z",
     "shell.execute_reply.started": "2025-05-06T14:35:34.048224Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, has_cactus]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels_df.shape)\n",
    "labels_df[labels_df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:35:34.064758Z",
     "iopub.status.busy": "2025-05-06T14:35:34.064342Z",
     "iopub.status.idle": "2025-05-06T14:35:34.076882Z",
     "shell.execute_reply": "2025-05-06T14:35:34.075783Z",
     "shell.execute_reply.started": "2025-05-06T14:35:34.064715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_cactus\n",
       "1    13136\n",
       "0     4364\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df['has_cactus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:35:34.080235Z",
     "iopub.status.busy": "2025-05-06T14:35:34.079831Z",
     "iopub.status.idle": "2025-05-06T14:35:34.100169Z",
     "shell.execute_reply": "2025-05-06T14:35:34.099165Z",
     "shell.execute_reply.started": "2025-05-06T14:35:34.080207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class pytorch_data(Dataset):\n",
    "    \n",
    "    def __init__(self, data_dir, transform, data_type=\"train\"):\n",
    "        # Get Image File Names\n",
    "        cdm_data = os.path.join(data_dir, data_type)\n",
    "        file_names = os.listdir(cdm_data)\n",
    "\n",
    "        all_image_paths = [os.path.join(cdm_data, f) for f in file_names if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "        print(f\"Found {len(all_image_paths)} images in directory.\")\n",
    "        print(f\"Sample filenames: {all_image_paths[:1]}\")\n",
    "\n",
    "        # Get Labels\n",
    "        labels_data = os.path.join(\"/kaggle/input/aml-challenge1/\", \"train.csv\")\n",
    "        labels_df = pd.read_csv(labels_data)\n",
    "\n",
    "        # Normalize index: remove extensions if present\n",
    "        labels_df['id'] = labels_df['id'].apply(lambda x: os.path.splitext(str(x))[0])\n",
    "        labels_df.set_index(\"id\", inplace=True)\n",
    "\n",
    "        print(f\"Labels dataframe length: {len(labels_df)}\")\n",
    "\n",
    "        # Extract only valid images (that have a label)\n",
    "        valid_filenames = []\n",
    "        labels = []\n",
    "\n",
    "        for f in all_image_paths:\n",
    "            filename = os.path.basename(f)  # get only file name\n",
    "            image_id = os.path.splitext(filename)[0]  # remove extension\n",
    "\n",
    "            if image_id in labels_df.index:\n",
    "                valid_filenames.append(f)\n",
    "                labels.append(labels_df.loc[image_id].values[0])\n",
    "            else:\n",
    "                print(f\"Warning: image '{filename}' has no matching label in train.csv\")\n",
    "\n",
    "        self.full_filenames = valid_filenames\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f\"Valid image-label pairs: {len(self.full_filenames)}\")\n",
    "        print(f\"First few labels: {self.labels[:5]}\")\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.full_filenames)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.full_filenames):\n",
    "            raise IndexError(f\"Index {idx} out of bounds for dataset of length {len(self.full_filenames)}\")\n",
    "\n",
    "        image = Image.open(self.full_filenames[idx])\n",
    "        image = self.transform(image)\n",
    "        return image, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:35:34.101632Z",
     "iopub.status.busy": "2025-05-06T14:35:34.101267Z",
     "iopub.status.idle": "2025-05-06T14:35:34.121132Z",
     "shell.execute_reply": "2025-05-06T14:35:34.119861Z",
     "shell.execute_reply.started": "2025-05-06T14:35:34.101587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# define transformation that converts a PIL image into PyTorch tensors\n",
    "import torchvision.transforms as transforms\n",
    "data_transformer = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Resize((32,32))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:35:34.122706Z",
     "iopub.status.busy": "2025-05-06T14:35:34.122288Z",
     "iopub.status.idle": "2025-05-06T14:35:34.663493Z",
     "shell.execute_reply": "2025-05-06T14:35:34.662656Z",
     "shell.execute_reply.started": "2025-05-06T14:35:34.122661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17500 images in directory.\n",
      "Sample filenames: ['/kaggle/input/aml-challenge1/train/train/5d3a7d32516a92cc0dc8c52af515eaa4.jpg']\n",
      "Labels dataframe length: 17500\n",
      "Valid image-label pairs: 17500\n",
      "First few labels: [1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Define an object of the custom dataset for the train folder.\n",
    "data_dir = path+'/train/'\n",
    "img_dataset = pytorch_data(data_dir, data_transformer, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:35:34.665183Z",
     "iopub.status.busy": "2025-05-06T14:35:34.664780Z",
     "iopub.status.idle": "2025-05-06T14:35:34.670130Z",
     "shell.execute_reply": "2025-05-06T14:35:34.669232Z",
     "shell.execute_reply.started": "2025-05-06T14:35:34.665149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# define transformation that converts a PIL image into PyTorch tensors\n",
    "data_transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32, 32))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:35:34.671483Z",
     "iopub.status.busy": "2025-05-06T14:35:34.671160Z",
     "iopub.status.idle": "2025-05-06T14:35:34.699184Z",
     "shell.execute_reply": "2025-05-06T14:35:34.697999Z",
     "shell.execute_reply.started": "2025-05-06T14:35:34.671453Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) tensor(0.2667) tensor(0.8627)\n"
     ]
    }
   ],
   "source": [
    "# Test a sample\n",
    "img, label = img_dataset[10]\n",
    "print(img.shape, torch.min(img), torch.max(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA AUGMENTATION CHE VA A RADDOPPIARE IL NUMERO DI SAMPLE DELLA CLASSE 0 AVENDO ALLA FINE CHE I SAMPLE DELLA CLASSE 0 SONO I 2/3 DEI SAMPLE DELLA CLASSE 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:45:47.390852Z",
     "iopub.status.busy": "2025-05-06T14:45:47.390514Z",
     "iopub.status.idle": "2025-05-06T14:46:49.264681Z",
     "shell.execute_reply": "2025-05-06T14:46:49.263678Z",
     "shell.execute_reply.started": "2025-05-06T14:45:47.390826Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4364/4364 [00:10<00:00, 399.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Aumentiamo le immagini della classe 0\n",
    "from torchvision.transforms import RandomRotation, ToTensor, Resize\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Trasformazione per augmentare\n",
    "augment_transform = transforms.Compose([\n",
    "    RandomRotation(degrees=10),\n",
    "    Resize((32, 32)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Trova solo immagini con etichetta 0\n",
    "images_class0 = [i for i in range(len(img_dataset)) if img_dataset.labels[i] == 0]\n",
    "\n",
    "# Duplichiamo queste immagini con trasformazione\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "for idx in tqdm(images_class0):\n",
    "    img_path = img_dataset.full_filenames[idx]\n",
    "    img = Image.open(img_path)\n",
    "    augmented_img = augment_transform(img)\n",
    "    augmented_images.append(augmented_img)\n",
    "    augmented_labels.append(0)\n",
    "\n",
    "# Stack immagini originali\n",
    "original_images = [img_dataset[i][0] for i in range(len(img_dataset))]\n",
    "original_labels = [img_dataset[i][1] for i in range(len(img_dataset))]\n",
    "\n",
    "# Combina immagini originali + augmentate\n",
    "all_images = torch.stack(original_images + augmented_images)\n",
    "all_labels = torch.tensor(original_labels + augmented_labels)\n",
    "\n",
    "# Nuovo Dataset custom con dati augmentati\n",
    "class AugmentedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "# Sostituisci img_dataset con quello nuovo\n",
    "img_dataset = AugmentedDataset(all_images, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***DIVISIONE NEI TRE SET TRAIN, VALIDATION, TEST DOPO AVER AUMENTATO I DATI DELLA CLASSE 0***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T15:16:22.595681Z",
     "iopub.status.busy": "2025-05-06T15:16:22.595389Z",
     "iopub.status.idle": "2025-05-06T15:16:23.146797Z",
     "shell.execute_reply": "2025-05-06T15:16:23.146037Z",
     "shell.execute_reply.started": "2025-05-06T15:16:22.595661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 15304\n",
      "validation dataset size: 3280\n",
      "test dataset size: 3280\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Estrai le etichette in modo sicuro\n",
    "labels = img_dataset.labels  # NON usare img_dataset[i][1]\n",
    "\n",
    "# Crea una lista di tutti gli indici\n",
    "all_indices = list(range(len(img_dataset)))\n",
    "\n",
    "# Split stratificato: Train (70%) e Temp (30%)\n",
    "train_idx, temp_idx = train_test_split(\n",
    "    all_indices, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Estrai le label corrispondenti agli indici temporanei per secondo split\n",
    "temp_labels = [labels[i] for i in temp_idx]\n",
    "\n",
    "# Split stratificato: Validation (15%) e Test (15%) da temp\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Crea i subset PyTorch\n",
    "train_ts = Subset(img_dataset, train_idx)\n",
    "val_ts = Subset(img_dataset, val_idx)\n",
    "test_ts = Subset(img_dataset, test_idx)\n",
    "\n",
    "# Visualizzazione\n",
    "print(\"train dataset size:\", len(train_ts))\n",
    "print(\"validation dataset size:\", len(val_ts))\n",
    "print(\"test dataset size:\", len(test_ts))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7341610,
     "sourceId": 11696839,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
