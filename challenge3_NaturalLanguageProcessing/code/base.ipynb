{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8074783,"sourceType":"datasetVersion","datasetId":4765148,"isSourceIdPinned":false}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"63c4205a","cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"michiard/sentiment-analysis-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:24:10.264744Z","iopub.execute_input":"2025-06-03T11:24:10.265060Z","iopub.status.idle":"2025-06-03T11:24:10.348439Z","shell.execute_reply.started":"2025-06-03T11:24:10.265034Z","shell.execute_reply":"2025-06-03T11:24:10.347431Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/sentiment-analysis-dataset\n","output_type":"stream"}],"execution_count":54},{"id":"a9d56684-ae98-4208-8171-253535d47a15","cell_type":"code","source":"import os\nimport pandas as pd\n\nprint(os.listdir(path))\n\ntrain_df = pd.read_csv(path+'/train.csv')\n\nprint(train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:24:13.096302Z","iopub.execute_input":"2025-06-03T11:24:13.096590Z","iopub.status.idle":"2025-06-03T11:24:13.210053Z","shell.execute_reply.started":"2025-06-03T11:24:13.096573Z","shell.execute_reply":"2025-06-03T11:24:13.209315Z"}},"outputs":[{"name":"stdout","text":"['sample_submission.csv', 'train.csv', 'test.csv']\n       textID                                               text  \\\n0  28ac06f416                        good luck with your auction   \n1  92098cf9a7  Hmm..You can`t judge a book by looking at its ...   \n2  7858ff28f2   Hello, yourself. Enjoy London. Watch out for ...   \n3  b0c9c67f32         We can`t even call you from belgium  sucks   \n4  7b36e9e7a5                                 not so good mood..   \n\n                                       selected_text sentiment  \n0                        good luck with your auction  positive  \n1  Hmm..You can`t judge a book by looking at its ...   neutral  \n2                                    They`re mental.  negative  \n3                                            m  suck  negative  \n4                                 not so good mood..  negative  \n","output_type":"stream"}],"execution_count":55},{"id":"c8c8735b-e0eb-4d66-aea4-5edb07cb0c07","cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"id":"377af365-1c32-4df3-a07a-47e705de261a","cell_type":"markdown","source":"## Checking null values","metadata":{}},{"id":"7cfde279-8db0-4068-ba16-910e7e3e592c","cell_type":"code","source":"print(train_df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:24:22.738401Z","iopub.execute_input":"2025-06-03T11:24:22.738699Z","iopub.status.idle":"2025-06-03T11:24:22.751571Z","shell.execute_reply.started":"2025-06-03T11:24:22.738678Z","shell.execute_reply":"2025-06-03T11:24:22.750688Z"}},"outputs":[{"name":"stdout","text":"textID           0\ntext             0\nselected_text    0\nsentiment        0\ndtype: int64\n","output_type":"stream"}],"execution_count":57},{"id":"5815aa97-f675-410a-b6c1-cd8151f4b8b1","cell_type":"markdown","source":"##  converting text to lowercase to ensure uniformity","metadata":{}},{"id":"ddc0f10b-dfed-4692-a205-f416374367b5","cell_type":"code","source":"train_df[\"text\"] = train_df[\"text\"].str.lower()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:24:27.283749Z","iopub.execute_input":"2025-06-03T11:24:27.284041Z","iopub.status.idle":"2025-06-03T11:24:27.296253Z","shell.execute_reply.started":"2025-06-03T11:24:27.284020Z","shell.execute_reply":"2025-06-03T11:24:27.295432Z"}},"outputs":[],"execution_count":58},{"id":"c3375d9d-4155-4fe9-a324-be3346f3107c","cell_type":"markdown","source":"## Removing irrelevant characters (like special symbols or HTML tags)","metadata":{}},{"id":"e0932387-aa25-49a3-83ef-5f7c442172b5","cell_type":"code","source":"import re\n\ndef clean_text(text):\n    text = re.sub(r\"http\\S+\", \"\", text)           # Remove URLs\n    text = re.sub(r\"@\\w+\", \"\", text)              # Remove mentions\n    text = re.sub(r\"#\\w+\", \"\", text)              # Remove hashtags\n    text = re.sub(r\"\\s+\", \" \", text).strip()      # Remove extra whitespaces\n    return text\n\ntrain_df[\"text\"] = train_df[\"text\"].apply(clean_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0aed057a-7488-4625-bd61-9a891df1336a","cell_type":"markdown","source":"## Tokenization","metadata":{}},{"id":"1b979f4e-d399-4a41-af5d-899ca52164a0","cell_type":"markdown","source":"punkt is a pretrained tokenizer model provided by NLTK (Natural Language Toolkit). It’s used by functions like nltk.word_tokenize to split text into words and punctuation tokens properly.\n\nWithout it, NLTK can’t perform word tokenization correctly.","metadata":{}},{"id":"96c205ba-7e09-4ba3-ab3b-4357fd305515","cell_type":"code","source":"from nltk.tokenize import word_tokenize\n\nimport nltk\nnltk.download('punkt')\n\n# Apply tokenization to each row in the 'text' column\ntrain_df['tokens'] = train_df['text'].apply(word_tokenize)\n\n# Preview the tokenized output\nprint(train_df[['text', 'tokens']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:24:34.153417Z","iopub.execute_input":"2025-06-03T11:24:34.153715Z","iopub.status.idle":"2025-06-03T11:24:37.647801Z","shell.execute_reply.started":"2025-06-03T11:24:34.153691Z","shell.execute_reply":"2025-06-03T11:24:37.646817Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"                                                text  \\\n0                        good luck with your auction   \n1  hmm..you can`t judge a book by looking at its ...   \n2   hello, yourself. enjoy london. watch out for ...   \n3         we can`t even call you from belgium  sucks   \n4                                 not so good mood..   \n\n                                              tokens  \n0                  [good, luck, with, your, auction]  \n1  [hmm, .., you, can, `, t, judge, a, book, by, ...  \n2  [hello, ,, yourself, ., enjoy, london, ., watc...  \n3  [we, can, `, t, even, call, you, from, belgium...  \n4                          [not, so, good, mood, ..]  \n","output_type":"stream"}],"execution_count":59},{"id":"5bc560d6-7802-4dc2-bb88-5af4b0897017","cell_type":"code","source":"!pip install nltk\nimport pandas as pd\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport nltk\n\nnltk.download('vader_lexicon')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:24:40.244745Z","iopub.execute_input":"2025-06-03T11:24:40.245102Z","iopub.status.idle":"2025-06-03T11:24:43.788557Z","shell.execute_reply.started":"2025-06-03T11:24:40.245079Z","shell.execute_reply":"2025-06-03T11:24:43.787407Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":60},{"id":"6ad0d846-7145-41e0-99c9-cf40a85dd74b","cell_type":"code","source":"sia = SentimentIntensityAnalyzer()\ndef get_sentiment_scores(text):\n    scores = sia.polarity_scores(text)\n    # scores example: {'neg': 0.0, 'neu': 0.453, 'pos': 0.547, 'compound': 0.5719}\n\n    # Determine polarity\n    if scores['compound'] >= 0.05:\n        polarity = 'positive'\n    elif scores['compound'] <= -0.05:\n        polarity = 'negative'\n    else:\n        polarity = 'neutral'\n\n    # Intensity can be the absolute value of compound score\n    intensity = abs(scores['compound'])\n\n    return polarity, intensity, scores\n\ntrain_df[['polarity', 'intensity', 'sentiment_scores']] = train_df['text'].apply(\n    lambda x: pd.Series(get_sentiment_scores(x))\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:24:49.869266Z","iopub.execute_input":"2025-06-03T11:24:49.870074Z","iopub.status.idle":"2025-06-03T11:24:56.602235Z","shell.execute_reply.started":"2025-06-03T11:24:49.870040Z","shell.execute_reply":"2025-06-03T11:24:56.601359Z"}},"outputs":[],"execution_count":61},{"id":"2f4a5bdc-9d4c-4a61-bfe6-4d643d683e2f","cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T11:25:14.583504Z","iopub.execute_input":"2025-06-03T11:25:14.583910Z","iopub.status.idle":"2025-06-03T11:25:14.612882Z","shell.execute_reply.started":"2025-06-03T11:25:14.583874Z","shell.execute_reply":"2025-06-03T11:25:14.611759Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"       textID                                               text  \\\n0  28ac06f416                        good luck with your auction   \n1  92098cf9a7  hmm..you can`t judge a book by looking at its ...   \n2  7858ff28f2   hello, yourself. enjoy london. watch out for ...   \n3  b0c9c67f32         we can`t even call you from belgium  sucks   \n4  7b36e9e7a5                                 not so good mood..   \n\n                                       selected_text sentiment  \\\n0                        good luck with your auction  positive   \n1  Hmm..You can`t judge a book by looking at its ...   neutral   \n2                                    They`re mental.  negative   \n3                                            m  suck  negative   \n4                                 not so good mood..  negative   \n\n                                              tokens  polarity  intensity  \\\n0                  [good, luck, with, your, auction]  positive     0.7096   \n1  [hmm, .., you, can, `, t, judge, a, book, by, ...   neutral     0.0000   \n2  [hello, ,, yourself, ., enjoy, london, ., watc...  positive     0.4939   \n3  [we, can, `, t, even, call, you, from, belgium...  negative     0.3612   \n4                          [not, so, good, mood, ..]  negative     0.3865   \n\n                                    sentiment_scores  \n0  {'neg': 0.0, 'neu': 0.337, 'pos': 0.663, 'comp...  \n1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n2  {'neg': 0.0, 'neu': 0.758, 'pos': 0.242, 'comp...  \n3  {'neg': 0.263, 'neu': 0.737, 'pos': 0.0, 'comp...  \n4  {'neg': 0.466, 'neu': 0.534, 'pos': 0.0, 'comp...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n      <th>polarity</th>\n      <th>intensity</th>\n      <th>sentiment_scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28ac06f416</td>\n      <td>good luck with your auction</td>\n      <td>good luck with your auction</td>\n      <td>positive</td>\n      <td>[good, luck, with, your, auction]</td>\n      <td>positive</td>\n      <td>0.7096</td>\n      <td>{'neg': 0.0, 'neu': 0.337, 'pos': 0.663, 'comp...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>92098cf9a7</td>\n      <td>hmm..you can`t judge a book by looking at its ...</td>\n      <td>Hmm..You can`t judge a book by looking at its ...</td>\n      <td>neutral</td>\n      <td>[hmm, .., you, can, `, t, judge, a, book, by, ...</td>\n      <td>neutral</td>\n      <td>0.0000</td>\n      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7858ff28f2</td>\n      <td>hello, yourself. enjoy london. watch out for ...</td>\n      <td>They`re mental.</td>\n      <td>negative</td>\n      <td>[hello, ,, yourself, ., enjoy, london, ., watc...</td>\n      <td>positive</td>\n      <td>0.4939</td>\n      <td>{'neg': 0.0, 'neu': 0.758, 'pos': 0.242, 'comp...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b0c9c67f32</td>\n      <td>we can`t even call you from belgium  sucks</td>\n      <td>m  suck</td>\n      <td>negative</td>\n      <td>[we, can, `, t, even, call, you, from, belgium...</td>\n      <td>negative</td>\n      <td>0.3612</td>\n      <td>{'neg': 0.263, 'neu': 0.737, 'pos': 0.0, 'comp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7b36e9e7a5</td>\n      <td>not so good mood..</td>\n      <td>not so good mood..</td>\n      <td>negative</td>\n      <td>[not, so, good, mood, ..]</td>\n      <td>negative</td>\n      <td>0.3865</td>\n      <td>{'neg': 0.466, 'neu': 0.534, 'pos': 0.0, 'comp...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":62}]}